{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import shap\n",
    "import lime\n",
    "from lime import lime_tabular\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "from fancyimpute import IterativeImputer as MICE\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import KMeansSMOTE\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, roc_auc_score, roc_curve, precision_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from joblib import dump, load\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def split_dataset(dataset, target_column, test_size=0.2):\n",
    "    \n",
    "    X = dataset.drop(columns=[target_column])\n",
    "    y = dataset[target_column]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "    logging.info(\"Dataset has been split and returned\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# This is given separately becuase, the other models are trained using prebuilt libraries\n",
    "def train_ann(X_train, y_train):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model = Sequential([\n",
    "        Input(shape=(X_train.shape[1],)),\n",
    "        Dense(12, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=150, batch_size=10, verbose=0)\n",
    "    end_time = time.time()\n",
    "\n",
    "    logging.info(f\"ANN has been trained in {end_time - start_time:.2f} seconds\")\n",
    "    return model\n",
    "\n",
    "def train_models(X_train, y_train):\n",
    "    \n",
    "    models = {}\n",
    "    param_grids = {\n",
    "        'RandomForest': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5]\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [3, 6],\n",
    "            'learning_rate': [0.01, 0.1]\n",
    "        },\n",
    "        'SVM': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        },\n",
    "        'LogisticRegression': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'penalty': ['l2']\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'max_depth': [3, 5, 7]\n",
    "        },\n",
    "        'KNN': {\n",
    "            'n_neighbors': [3, 5, 7],\n",
    "            'weights': ['uniform', 'distance']\n",
    "        }\n",
    "    }\n",
    "\n",
    "    models['ANN'] = train_ann(X_train, y_train)\n",
    "\n",
    "    for model_name, param_grid in param_grids.items():\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            if model_name == 'RandomForest':\n",
    "                model = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
    "            elif model_name == 'XGBoost':\n",
    "                model = GridSearchCV(XGBClassifier(), param_grid, cv=5)\n",
    "            elif model_name == 'SVM':\n",
    "                model = GridSearchCV(SVC(probability=True), param_grid, cv=5)\n",
    "            elif model_name == 'LogisticRegression':\n",
    "                model = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
    "            elif model_name == 'GradientBoosting':\n",
    "                model = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5)\n",
    "            elif model_name == 'KNN':\n",
    "                model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
    "\n",
    "            model.fit(X_train, y_train)\n",
    "            models[model_name] = model.best_estimator_\n",
    "            end_time = time.time()\n",
    "            logging.info(f\"{model_name} has been trained in {end_time - start_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error training {model_name}: {e}\")\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        nb = GaussianNB()\n",
    "        nb.fit(X_train, y_train)\n",
    "        models['NaiveBayes'] = nb\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Naive Bayes has been trained in {end_time - start_time:.2f} seconds\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error training Naive Bayes: {e}\")\n",
    "\n",
    "    return models\n",
    "\n",
    "def test_models(models, X_test):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions = {}\n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            if name == 'ANN':\n",
    "                predictions[name] = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "            else:\n",
    "                predictions[name] = model.predict(X_test)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error testing {name}: {e}\")\n",
    "    end_time = time.time()\n",
    "\n",
    "    logging.info(f\"Models have been tested in {end_time - start_time:.2f} seconds\")\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluate_models(models, predictions, y_test, X_test):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    metrics = {}\n",
    "    \n",
    "    for name, y_pred in predictions.items():\n",
    "        try:\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            \n",
    "            if hasattr(models[name], \"predict_proba\"):\n",
    "                auc = roc_auc_score(y_test, models[name].predict_proba(X_test)[:, 1])\n",
    "            else:\n",
    "                auc = roc_auc_score(y_test, models[name].predict(X_test))\n",
    "            \n",
    "            # Calculate specificity\n",
    "            if cm.shape == (2, 2):\n",
    "                tn, fp, fn, tp = cm.ravel()\n",
    "                specificity = tn / (tn + fp)\n",
    "            else:\n",
    "                specificity = 0  # or handle the case appropriately\n",
    "            \n",
    "            # Calculate G-mean\n",
    "            g_mean = np.sqrt(recall * specificity)\n",
    "            \n",
    "            # Calculate Kappa statistic\n",
    "            kappa = cohen_kappa_score(y_test, y_pred)\n",
    "            \n",
    "            metrics[name] = {\n",
    "                'accuracy': accuracy,\n",
    "                'confusion_matrix': cm,\n",
    "                'f1_score': f1,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'auc_roc': auc,\n",
    "                'g_mean': g_mean,\n",
    "                'kappa': kappa\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error evaluating {name}: {e}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    logging.info(f\"Models have been evaluated in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def explainability_shap(models, df_name, X_test, feature_names):\n",
    "\n",
    "    \n",
    "    # Ensure X_test is a DataFrame with named columns\n",
    "    X_test = pd.DataFrame(X_test, columns=feature_names).reset_index(drop=True)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if name == 'ANN':\n",
    "            continue\n",
    "        try:\n",
    "            if name in ['RandomForest', 'XGBoost', 'GradientBoosting']:\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "            \n",
    "            # No existing methods to analyse other models using SHAP, so only these three models.\n",
    "            \n",
    "            shap_values = explainer.shap_values(X_test)\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values[1] if isinstance(shap_values, list) else shap_values, \n",
    "                              X_test, plot_type=\"bar\", show=False, max_display=10)\n",
    "            plt.title(f\"Top 10 Most Important Features - {name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"C:\\\\Users\\\\dev\\\\Desktop\\\\MSC thesis\\\\Code\\\\final_codes\\\\Lime and shap graphs\\\\{df_name}_shap_importance_{name}.png\")\n",
    "            plt.close()\n",
    "            logging.info(f\"SHAP explanations for {name} created and saved\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating SHAP explanations for {name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def explainability_lime(models, df_name, X_train, X_test, feature_names):\n",
    "    \n",
    "    \n",
    "    # Ensure X_train and X_test are DataFrames with named columns\n",
    "    X_train = pd.DataFrame(X_train, columns=feature_names).reset_index(drop=True)\n",
    "    X_test = pd.DataFrame(X_test, columns=feature_names).reset_index(drop=True)\n",
    "    \n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train.values,  # Use .values to get numpy array\n",
    "        feature_names=feature_names, \n",
    "        class_names=['Negative', 'Positive'], \n",
    "        mode='classification'\n",
    "    )\n",
    "    for name, model in models.items():\n",
    "        if name == 'ANN':\n",
    "            continue\n",
    "        try:\n",
    "            i = np.random.randint(0, X_test.shape[0])\n",
    "            exp = explainer.explain_instance(\n",
    "                X_test.iloc[i].values,  # Use .iloc[i].values to get numpy array\n",
    "                model.predict_proba, \n",
    "                num_features=6\n",
    "            )\n",
    "            feature_importance = pd.DataFrame(exp.as_list(), columns=['Feature', 'Importance'])\n",
    "            feature_importance['Absolute Importance'] = abs(feature_importance['Importance'])\n",
    "            feature_importance = feature_importance.sort_values('Absolute Importance', ascending=True)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            colors = ['red' if imp < 0 else 'green' for imp in feature_importance['Importance']]\n",
    "            plt.barh(feature_importance['Feature'], feature_importance['Importance'], color=colors)\n",
    "            plt.title(f\"LIME Explanation for {name}\\nTop 6 Features' Impact on Prediction\")\n",
    "            plt.xlabel('Impact on Prediction (Red = Negative, Green = Positive)')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"C:\\\\Users\\\\dev\\\\Desktop\\\\MSC thesis\\\\Code\\\\final_codes\\\\Lime and shap graphs\\\\{df_name}_lime_explanation_{name}.png\")\n",
    "            plt.close()\n",
    "            logging.info(f\"LIME explanation for {name} created and saved\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating LIME explanations for {name}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def interpret_results(models, X_test, feature_names):\n",
    "\n",
    "    \n",
    "    summary = \"Model Interpretation Summary:\\n\\n\"\n",
    "    for name, model in models.items():\n",
    "        if name == 'ANN':\n",
    "            continue\n",
    "        summary += f\"{name} Model:\\n\"\n",
    "        summary += f\"Feature Importance from {name} Model:\\n\"\n",
    "        try:\n",
    "            if name in ['RandomForest', 'XGBoost', 'GradientBoosting']:\n",
    "                importances = model.feature_importances_\n",
    "                importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "                importance_df = importance_df.sort_values('Importance', ascending=False).head(10)\n",
    "            else:\n",
    "                importances = model.coef_[0] if hasattr(model, 'coef_') else None\n",
    "                importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "                importance_df = importance_df.sort_values('Importance', ascending=False).head(10)\n",
    "            summary += importance_df.to_string(index=False)\n",
    "            summary += \"\\n\\n\"\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error interpreting results for {name}: {e}\")\n",
    "    logging.info(\"Model interpretation summary created\")\n",
    "    return summary\n",
    "\n",
    "\n",
    "def save_models(models, directory='models'):\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            if name == 'ANN':\n",
    "                model.save(os.path.join(directory, f'{name}_model.h5'))\n",
    "            else:\n",
    "                dump(model, os.path.join(directory, f'{name}_model.joblib'))\n",
    "            logging.info(f\"{name} model saved\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving {name} model: {e}\")\n",
    "\n",
    "\n",
    "# Use only if needed to run back with best models\n",
    "def load_models(directory='models'):\n",
    "    \n",
    "    models = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        model_name, ext = os.path.splitext(filename)\n",
    "        try:\n",
    "            if ext == '.h5':\n",
    "                models[model_name] = load_model(os.path.join(directory, filename))\n",
    "            elif ext == '.joblib':\n",
    "                models[model_name] = load(os.path.join(directory, filename))\n",
    "            logging.info(f\"{model_name} model loaded\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading {model_name} model: {e}\")\n",
    "    return models\n",
    "\n",
    "\n",
    "def main(dataset, target_column, name):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_dataset(dataset, target_column)\n",
    "\n",
    "    # Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    logging.info(\"Data has been standardized\")\n",
    "\n",
    "    models = train_models(X_train, y_train)\n",
    "    predictions = test_models(models, X_test)\n",
    "    metrics = evaluate_models(models, predictions, y_test, X_test)\n",
    "\n",
    "    explainability_shap(models, name, X_test, feature_names=dataset.drop(columns=[target_column]).columns)\n",
    "    explainability_lime(models, name, X_train, X_test, feature_names=dataset.drop(columns=[target_column]).columns)\n",
    "\n",
    "    # save_models(models)\n",
    "    logging.info(\"Models have been saved\")\n",
    "\n",
    "    # Interpret results\n",
    "    summary = interpret_results(models, X_test, feature_names=dataset.drop(columns=[target_column]).columns)\n",
    "    print(summary)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def modelling_gs(df, name):\n",
    "    \n",
    "    target_column = 'LABEL'  # Replace with your target column\n",
    "    results = main(df, target_column, name)\n",
    "    logging.info(\"Results have been documented.\")\n",
    "    return results\n",
    "\n",
    "# To run the modelling function with a dataset 'df':\n",
    "# results = modelling_gs(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:38:30,825 - INFO - Dataset has been split and returned\n",
      "2024-07-22 19:38:30,833 - INFO - Data has been standardized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets are read into dataframes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:41:26,504 - INFO - ANN has been trained in 175.67 seconds\n",
      "2024-07-22 20:00:24,599 - INFO - RandomForest has been trained in 1138.09 seconds\n",
      "2024-07-22 20:00:39,535 - INFO - XGBoost has been trained in 14.94 seconds\n",
      "2024-07-22 20:20:01,899 - INFO - SVM has been trained in 1162.36 seconds\n",
      "2024-07-22 20:20:02,548 - INFO - LogisticRegression has been trained in 0.65 seconds\n",
      "2024-07-22 21:10:33,321 - INFO - GradientBoosting has been trained in 3030.77 seconds\n",
      "2024-07-22 21:10:36,352 - INFO - KNN has been trained in 3.03 seconds\n",
      "2024-07-22 21:10:36,364 - INFO - Naive Bayes has been trained in 0.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:10:39,627 - INFO - Models have been tested in 3.26 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:10:42,969 - INFO - Models have been evaluated in 3.34 seconds\n",
      "2024-07-22 21:12:27,140 - INFO - SHAP explanations for RandomForest created and saved\n",
      "2024-07-22 21:12:28,644 - INFO - SHAP explanations for XGBoost created and saved\n",
      "2024-07-22 21:12:30,096 - INFO - SHAP explanations for SVM created and saved\n",
      "2024-07-22 21:12:31,551 - INFO - SHAP explanations for LogisticRegression created and saved\n",
      "2024-07-22 21:12:52,401 - INFO - SHAP explanations for GradientBoosting created and saved\n",
      "2024-07-22 21:13:13,315 - INFO - SHAP explanations for KNN created and saved\n",
      "2024-07-22 21:13:34,049 - INFO - SHAP explanations for NaiveBayes created and saved\n",
      "2024-07-22 21:13:34,455 - INFO - LIME explanation for RandomForest created and saved\n",
      "2024-07-22 21:13:34,761 - INFO - LIME explanation for XGBoost created and saved\n",
      "2024-07-22 21:13:37,726 - INFO - LIME explanation for SVM created and saved\n",
      "2024-07-22 21:13:38,009 - INFO - LIME explanation for LogisticRegression created and saved\n",
      "2024-07-22 21:13:38,344 - INFO - LIME explanation for GradientBoosting created and saved\n",
      "2024-07-22 21:13:38,749 - INFO - LIME explanation for KNN created and saved\n",
      "2024-07-22 21:13:39,037 - INFO - LIME explanation for NaiveBayes created and saved\n",
      "2024-07-22 21:13:39,037 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024-07-22 21:13:39,068 - INFO - ANN model saved\n",
      "2024-07-22 21:13:39,103 - INFO - RandomForest model saved\n",
      "2024-07-22 21:13:39,113 - INFO - XGBoost model saved\n",
      "2024-07-22 21:13:39,115 - INFO - SVM model saved\n",
      "2024-07-22 21:13:39,117 - INFO - LogisticRegression model saved\n",
      "2024-07-22 21:13:39,146 - INFO - GradientBoosting model saved\n",
      "2024-07-22 21:13:39,150 - INFO - KNN model saved\n",
      "2024-07-22 21:13:39,152 - INFO - NaiveBayes model saved\n",
      "2024-07-22 21:13:39,152 - INFO - Models have been saved\n",
      "2024-07-22 21:13:39,179 - INFO - Model interpretation summary created\n",
      "2024-07-22 21:13:39,181 - INFO - Results have been documented.\n",
      "2024-07-22 21:13:39,200 - INFO - Dataset has been split and returned\n",
      "2024-07-22 21:13:39,211 - INFO - Data has been standardized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Interpretation Summary:\n",
      "\n",
      "RandomForest Model:\n",
      "Feature Importance from RandomForest Model:\n",
      "                          Feature  Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.200358\n",
      "              Leverage_Ratios_PC1    0.194320\n",
      "      Cost_and_Expense_Ratios_PC1    0.177273\n",
      "      Cost_and_Expense_Ratios_PC2    0.097519\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.056907\n",
      "         Profitability_Ratios_PC1    0.036241\n",
      "              Activity_Ratios_PC1    0.030568\n",
      "             Cash_Flow_Ratios_PC1    0.028284\n",
      "             Cash_Flow_Ratios_PC2    0.026895\n",
      "         Profitability_Ratios_PC2    0.025529\n",
      "\n",
      "XGBoost Model:\n",
      "Feature Importance from XGBoost Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.416653\n",
      "      Cost_and_Expense_Ratios_PC1    0.090932\n",
      "      Cost_and_Expense_Ratios_PC2    0.081417\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.051538\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.051497\n",
      "              Activity_Ratios_PC1    0.039150\n",
      "         Profitability_Ratios_PC2    0.031309\n",
      "                Growth_Ratios_PC2    0.031272\n",
      "             Cash_Flow_Ratios_PC2    0.030441\n",
      "             Per_Share_Ratios_PC2    0.030015\n",
      "\n",
      "SVM Model:\n",
      "Feature Importance from SVM Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "LogisticRegression Model:\n",
      "Feature Importance from LogisticRegression Model:\n",
      "                          Feature  Importance\n",
      "      Cost_and_Expense_Ratios_PC1    7.740283\n",
      "         Profitability_Ratios_PC2    4.521865\n",
      "              Leverage_Ratios_PC1    1.483903\n",
      "         Profitability_Ratios_PC1    1.313461\n",
      "             Per_Share_Ratios_PC1    1.018142\n",
      "             Per_Share_Ratios_PC2    0.350339\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.049603\n",
      "                Growth_Ratios_PC2   -0.001767\n",
      "              Leverage_Ratios_PC2   -0.022443\n",
      "             Cash_Flow_Ratios_PC2   -0.203653\n",
      "\n",
      "GradientBoosting Model:\n",
      "Feature Importance from GradientBoosting Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.523994\n",
      "      Cost_and_Expense_Ratios_PC1    0.109606\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.053792\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.050282\n",
      "      Cost_and_Expense_Ratios_PC2    0.043777\n",
      "         Profitability_Ratios_PC2    0.031075\n",
      "              Activity_Ratios_PC1    0.025059\n",
      "                Growth_Ratios_PC2    0.023767\n",
      "             Per_Share_Ratios_PC2    0.022335\n",
      "         Profitability_Ratios_PC1    0.020555\n",
      "\n",
      "KNN Model:\n",
      "Feature Importance from KNN Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "NaiveBayes Model:\n",
      "Feature Importance from NaiveBayes Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "\n",
      "_______________________________________________________________________________\n",
      " Total time taken by ADASYN_AE_3_PCA: 95.14 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:16:32,506 - INFO - ANN has been trained in 173.30 seconds\n",
      "2024-07-22 21:36:01,842 - INFO - RandomForest has been trained in 1169.34 seconds\n",
      "2024-07-22 21:36:16,381 - INFO - XGBoost has been trained in 14.54 seconds\n",
      "2024-07-22 21:56:35,709 - INFO - SVM has been trained in 1219.33 seconds\n",
      "c:\\Users\\dev\\Desktop\\MSC thesis\\Code\\mscthesis\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2024-07-22 21:56:36,572 - INFO - LogisticRegression has been trained in 0.86 seconds\n",
      "2024-07-22 22:46:27,442 - INFO - GradientBoosting has been trained in 2990.87 seconds\n",
      "2024-07-22 22:46:30,243 - INFO - KNN has been trained in 2.80 seconds\n",
      "2024-07-22 22:46:30,251 - INFO - Naive Bayes has been trained in 0.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:46:33,344 - INFO - Models have been tested in 3.09 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:46:36,545 - INFO - Models have been evaluated in 3.20 seconds\n",
      "2024-07-22 22:50:29,353 - INFO - SHAP explanations for RandomForest created and saved\n",
      "2024-07-22 22:50:31,246 - INFO - SHAP explanations for XGBoost created and saved\n",
      "2024-07-22 22:50:32,648 - INFO - SHAP explanations for SVM created and saved\n",
      "2024-07-22 22:50:34,052 - INFO - SHAP explanations for LogisticRegression created and saved\n",
      "2024-07-22 22:50:54,889 - INFO - SHAP explanations for GradientBoosting created and saved\n",
      "2024-07-22 22:51:15,677 - INFO - SHAP explanations for KNN created and saved\n",
      "2024-07-22 22:51:36,484 - INFO - SHAP explanations for NaiveBayes created and saved\n",
      "2024-07-22 22:51:36,905 - INFO - LIME explanation for RandomForest created and saved\n",
      "2024-07-22 22:51:37,210 - INFO - LIME explanation for XGBoost created and saved\n",
      "2024-07-22 22:51:39,884 - INFO - LIME explanation for SVM created and saved\n",
      "2024-07-22 22:51:40,158 - INFO - LIME explanation for LogisticRegression created and saved\n",
      "2024-07-22 22:51:40,487 - INFO - LIME explanation for GradientBoosting created and saved\n",
      "2024-07-22 22:51:40,882 - INFO - LIME explanation for KNN created and saved\n",
      "2024-07-22 22:51:41,160 - INFO - LIME explanation for NaiveBayes created and saved\n",
      "2024-07-22 22:51:41,161 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024-07-22 22:51:41,179 - INFO - ANN model saved\n",
      "2024-07-22 22:51:41,242 - INFO - RandomForest model saved\n",
      "2024-07-22 22:51:41,251 - INFO - XGBoost model saved\n",
      "2024-07-22 22:51:41,255 - INFO - SVM model saved\n",
      "2024-07-22 22:51:41,256 - INFO - LogisticRegression model saved\n",
      "2024-07-22 22:51:41,286 - INFO - GradientBoosting model saved\n",
      "2024-07-22 22:51:41,290 - INFO - KNN model saved\n",
      "2024-07-22 22:51:41,292 - INFO - NaiveBayes model saved\n",
      "2024-07-22 22:51:41,293 - INFO - Models have been saved\n",
      "2024-07-22 22:51:41,319 - INFO - Model interpretation summary created\n",
      "2024-07-22 22:51:41,326 - INFO - Results have been documented.\n",
      "2024-07-22 22:51:41,344 - INFO - Dataset has been split and returned\n",
      "2024-07-22 22:51:41,353 - INFO - Data has been standardized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Interpretation Summary:\n",
      "\n",
      "RandomForest Model:\n",
      "Feature Importance from RandomForest Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.222312\n",
      "      Cost_and_Expense_Ratios_PC1    0.197523\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.136176\n",
      "      Cost_and_Expense_Ratios_PC2    0.097559\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.050811\n",
      "              Leverage_Ratios_PC2    0.044592\n",
      "         Profitability_Ratios_PC1    0.035438\n",
      "              Activity_Ratios_PC1    0.028526\n",
      "             Cash_Flow_Ratios_PC1    0.026148\n",
      "              Activity_Ratios_PC2    0.026077\n",
      "\n",
      "XGBoost Model:\n",
      "Feature Importance from XGBoost Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.434680\n",
      "      Cost_and_Expense_Ratios_PC1    0.155829\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.058382\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.056347\n",
      "             Cash_Flow_Ratios_PC1    0.035663\n",
      "              Activity_Ratios_PC1    0.030532\n",
      "             Per_Share_Ratios_PC2    0.029561\n",
      "                Growth_Ratios_PC1    0.026086\n",
      "              Activity_Ratios_PC2    0.024546\n",
      "              Leverage_Ratios_PC2    0.024095\n",
      "\n",
      "SVM Model:\n",
      "Feature Importance from SVM Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "LogisticRegression Model:\n",
      "Feature Importance from LogisticRegression Model:\n",
      "                          Feature  Importance\n",
      "             Per_Share_Ratios_PC1   11.271955\n",
      "         Profitability_Ratios_PC2    3.747069\n",
      "              Leverage_Ratios_PC1    1.999951\n",
      "         Profitability_Ratios_PC1    0.542455\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.348404\n",
      "             Per_Share_Ratios_PC2    0.161889\n",
      "                Growth_Ratios_PC2   -0.041488\n",
      "                Growth_Ratios_PC1   -0.287880\n",
      "              Leverage_Ratios_PC2   -0.446575\n",
      "             Cash_Flow_Ratios_PC2   -0.482558\n",
      "\n",
      "GradientBoosting Model:\n",
      "Feature Importance from GradientBoosting Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.486903\n",
      "      Cost_and_Expense_Ratios_PC1    0.176826\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.066603\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.049707\n",
      "             Cash_Flow_Ratios_PC1    0.029525\n",
      "              Activity_Ratios_PC1    0.027465\n",
      "             Per_Share_Ratios_PC2    0.022416\n",
      "         Profitability_Ratios_PC1    0.019877\n",
      "         Profitability_Ratios_PC2    0.018904\n",
      "                Growth_Ratios_PC1    0.018308\n",
      "\n",
      "KNN Model:\n",
      "Feature Importance from KNN Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "NaiveBayes Model:\n",
      "Feature Importance from NaiveBayes Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "\n",
      "_______________________________________________________________________________\n",
      " Total time taken by ADASYN_MICE_3_PCA: 98.04 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:54:35,629 - INFO - ANN has been trained in 174.28 seconds\n",
      "2024-07-22 23:13:08,003 - INFO - RandomForest has been trained in 1112.37 seconds\n",
      "2024-07-22 23:13:21,551 - INFO - XGBoost has been trained in 13.55 seconds\n",
      "2024-07-22 23:27:39,188 - INFO - SVM has been trained in 857.64 seconds\n",
      "2024-07-22 23:27:39,874 - INFO - LogisticRegression has been trained in 0.69 seconds\n",
      "2024-07-23 00:17:40,787 - INFO - GradientBoosting has been trained in 3000.91 seconds\n",
      "2024-07-23 00:17:43,589 - INFO - KNN has been trained in 2.80 seconds\n",
      "2024-07-23 00:17:43,597 - INFO - Naive Bayes has been trained in 0.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 00:17:46,242 - INFO - Models have been tested in 2.64 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 00:17:48,949 - INFO - Models have been evaluated in 2.71 seconds\n",
      "2024-07-23 00:21:03,378 - INFO - SHAP explanations for RandomForest created and saved\n",
      "2024-07-23 00:21:04,802 - INFO - SHAP explanations for XGBoost created and saved\n",
      "2024-07-23 00:21:06,133 - INFO - SHAP explanations for SVM created and saved\n",
      "2024-07-23 00:21:07,486 - INFO - SHAP explanations for LogisticRegression created and saved\n",
      "2024-07-23 00:21:28,684 - INFO - SHAP explanations for GradientBoosting created and saved\n",
      "2024-07-23 00:21:49,765 - INFO - SHAP explanations for KNN created and saved\n",
      "2024-07-23 00:22:10,790 - INFO - SHAP explanations for NaiveBayes created and saved\n",
      "2024-07-23 00:22:11,208 - INFO - LIME explanation for RandomForest created and saved\n",
      "2024-07-23 00:22:11,508 - INFO - LIME explanation for XGBoost created and saved\n",
      "2024-07-23 00:22:13,615 - INFO - LIME explanation for SVM created and saved\n",
      "2024-07-23 00:22:13,894 - INFO - LIME explanation for LogisticRegression created and saved\n",
      "2024-07-23 00:22:14,226 - INFO - LIME explanation for GradientBoosting created and saved\n",
      "2024-07-23 00:22:14,596 - INFO - LIME explanation for KNN created and saved\n",
      "2024-07-23 00:22:14,876 - INFO - LIME explanation for NaiveBayes created and saved\n",
      "2024-07-23 00:22:14,877 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024-07-23 00:22:14,893 - INFO - ANN model saved\n",
      "2024-07-23 00:22:15,136 - INFO - RandomForest model saved\n",
      "2024-07-23 00:22:15,144 - INFO - XGBoost model saved\n",
      "2024-07-23 00:22:15,146 - INFO - SVM model saved\n",
      "2024-07-23 00:22:15,148 - INFO - LogisticRegression model saved\n",
      "2024-07-23 00:22:15,177 - INFO - GradientBoosting model saved\n",
      "2024-07-23 00:22:15,181 - INFO - KNN model saved\n",
      "2024-07-23 00:22:15,183 - INFO - NaiveBayes model saved\n",
      "2024-07-23 00:22:15,184 - INFO - Models have been saved\n",
      "2024-07-23 00:22:15,211 - INFO - Model interpretation summary created\n",
      "2024-07-23 00:22:15,214 - INFO - Results have been documented.\n",
      "2024-07-23 00:22:15,231 - INFO - Dataset has been split and returned\n",
      "2024-07-23 00:22:15,241 - INFO - Data has been standardized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Interpretation Summary:\n",
      "\n",
      "RandomForest Model:\n",
      "Feature Importance from RandomForest Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.272774\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.189410\n",
      "      Cost_and_Expense_Ratios_PC1    0.161514\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.076516\n",
      "      Cost_and_Expense_Ratios_PC2    0.074826\n",
      "         Profitability_Ratios_PC1    0.036442\n",
      "             Cash_Flow_Ratios_PC2    0.030916\n",
      "             Cash_Flow_Ratios_PC1    0.023327\n",
      "              Activity_Ratios_PC2    0.021369\n",
      "              Activity_Ratios_PC1    0.021331\n",
      "\n",
      "XGBoost Model:\n",
      "Feature Importance from XGBoost Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.578870\n",
      "      Cost_and_Expense_Ratios_PC1    0.096509\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.043744\n",
      "              Activity_Ratios_PC1    0.035837\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.034951\n",
      "              Activity_Ratios_PC2    0.032172\n",
      "             Cash_Flow_Ratios_PC2    0.028192\n",
      "             Per_Share_Ratios_PC1    0.021860\n",
      "             Per_Share_Ratios_PC2    0.021369\n",
      "         Profitability_Ratios_PC2    0.018247\n",
      "\n",
      "SVM Model:\n",
      "Feature Importance from SVM Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "LogisticRegression Model:\n",
      "Feature Importance from LogisticRegression Model:\n",
      "                          Feature  Importance\n",
      "      Cost_and_Expense_Ratios_PC1    9.647082\n",
      "         Profitability_Ratios_PC2    6.297514\n",
      "              Leverage_Ratios_PC1    2.232682\n",
      "         Profitability_Ratios_PC1    0.871257\n",
      "             Per_Share_Ratios_PC1    0.778627\n",
      "             Cash_Flow_Ratios_PC2    0.339968\n",
      "             Per_Share_Ratios_PC2    0.109813\n",
      "              Leverage_Ratios_PC2    0.025600\n",
      "                Growth_Ratios_PC2   -0.006458\n",
      "Liquidity_and_Coverage_Ratios_PC2   -0.285448\n",
      "\n",
      "GradientBoosting Model:\n",
      "Feature Importance from GradientBoosting Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.666989\n",
      "      Cost_and_Expense_Ratios_PC1    0.106490\n",
      "             Cash_Flow_Ratios_PC2    0.038041\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.034749\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.026954\n",
      "         Profitability_Ratios_PC1    0.016282\n",
      "              Activity_Ratios_PC1    0.015599\n",
      "              Activity_Ratios_PC2    0.015084\n",
      "             Per_Share_Ratios_PC1    0.013605\n",
      "             Cash_Flow_Ratios_PC1    0.013187\n",
      "\n",
      "KNN Model:\n",
      "Feature Importance from KNN Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "NaiveBayes Model:\n",
      "Feature Importance from NaiveBayes Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "\n",
      "_______________________________________________________________________________\n",
      " Total time taken by KMSMOTE_AE_3_PCA: 90.56 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 00:25:08,859 - INFO - ANN has been trained in 173.62 seconds\n",
      "2024-07-23 00:43:55,599 - INFO - RandomForest has been trained in 1126.74 seconds\n",
      "2024-07-23 00:44:09,147 - INFO - XGBoost has been trained in 13.55 seconds\n",
      "2024-07-23 00:58:37,938 - INFO - SVM has been trained in 868.79 seconds\n",
      "c:\\Users\\dev\\Desktop\\MSC thesis\\Code\\mscthesis\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2024-07-23 00:58:38,761 - INFO - LogisticRegression has been trained in 0.82 seconds\n",
      "2024-07-23 01:48:43,407 - INFO - GradientBoosting has been trained in 3004.65 seconds\n",
      "2024-07-23 01:48:46,234 - INFO - KNN has been trained in 2.83 seconds\n",
      "2024-07-23 01:48:46,241 - INFO - Naive Bayes has been trained in 0.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 01:48:48,633 - INFO - Models have been tested in 2.39 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 531us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 01:48:51,082 - INFO - Models have been evaluated in 2.45 seconds\n",
      "2024-07-23 01:51:57,967 - INFO - SHAP explanations for RandomForest created and saved\n",
      "2024-07-23 01:51:59,397 - INFO - SHAP explanations for XGBoost created and saved\n",
      "2024-07-23 01:52:00,751 - INFO - SHAP explanations for SVM created and saved\n",
      "2024-07-23 01:52:02,109 - INFO - SHAP explanations for LogisticRegression created and saved\n",
      "2024-07-23 01:52:22,769 - INFO - SHAP explanations for GradientBoosting created and saved\n",
      "2024-07-23 01:52:43,522 - INFO - SHAP explanations for KNN created and saved\n",
      "2024-07-23 01:53:04,118 - INFO - SHAP explanations for NaiveBayes created and saved\n",
      "2024-07-23 01:53:04,539 - INFO - LIME explanation for RandomForest created and saved\n",
      "2024-07-23 01:53:04,843 - INFO - LIME explanation for XGBoost created and saved\n",
      "2024-07-23 01:53:06,838 - INFO - LIME explanation for SVM created and saved\n",
      "2024-07-23 01:53:07,110 - INFO - LIME explanation for LogisticRegression created and saved\n",
      "2024-07-23 01:53:07,434 - INFO - LIME explanation for GradientBoosting created and saved\n",
      "2024-07-23 01:53:07,823 - INFO - LIME explanation for KNN created and saved\n",
      "2024-07-23 01:53:08,104 - INFO - LIME explanation for NaiveBayes created and saved\n",
      "2024-07-23 01:53:08,105 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024-07-23 01:53:08,122 - INFO - ANN model saved\n",
      "2024-07-23 01:53:08,181 - INFO - RandomForest model saved\n",
      "2024-07-23 01:53:08,190 - INFO - XGBoost model saved\n",
      "2024-07-23 01:53:08,193 - INFO - SVM model saved\n",
      "2024-07-23 01:53:08,194 - INFO - LogisticRegression model saved\n",
      "2024-07-23 01:53:08,221 - INFO - GradientBoosting model saved\n",
      "2024-07-23 01:53:08,226 - INFO - KNN model saved\n",
      "2024-07-23 01:53:08,228 - INFO - NaiveBayes model saved\n",
      "2024-07-23 01:53:08,228 - INFO - Models have been saved\n",
      "2024-07-23 01:53:08,254 - INFO - Model interpretation summary created\n",
      "2024-07-23 01:53:08,257 - INFO - Results have been documented.\n",
      "2024-07-23 01:53:08,273 - INFO - Dataset has been split and returned\n",
      "2024-07-23 01:53:08,283 - INFO - Data has been standardized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Interpretation Summary:\n",
      "\n",
      "RandomForest Model:\n",
      "Feature Importance from RandomForest Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.295880\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.179006\n",
      "      Cost_and_Expense_Ratios_PC1    0.138214\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.066711\n",
      "      Cost_and_Expense_Ratios_PC2    0.063595\n",
      "         Profitability_Ratios_PC1    0.045965\n",
      "              Activity_Ratios_PC2    0.043580\n",
      "             Cash_Flow_Ratios_PC2    0.029392\n",
      "              Activity_Ratios_PC1    0.027914\n",
      "         Profitability_Ratios_PC2    0.019790\n",
      "\n",
      "XGBoost Model:\n",
      "Feature Importance from XGBoost Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.623866\n",
      "      Cost_and_Expense_Ratios_PC1    0.082495\n",
      "              Activity_Ratios_PC2    0.037848\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.035664\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.029252\n",
      "              Activity_Ratios_PC1    0.026884\n",
      "             Cash_Flow_Ratios_PC2    0.024805\n",
      "             Per_Share_Ratios_PC1    0.020525\n",
      "         Profitability_Ratios_PC2    0.019611\n",
      "                Growth_Ratios_PC1    0.017180\n",
      "\n",
      "SVM Model:\n",
      "Feature Importance from SVM Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "LogisticRegression Model:\n",
      "Feature Importance from LogisticRegression Model:\n",
      "                          Feature  Importance\n",
      "             Per_Share_Ratios_PC1    7.041636\n",
      "         Profitability_Ratios_PC2    5.097689\n",
      "              Leverage_Ratios_PC1    2.613960\n",
      "         Profitability_Ratios_PC1    0.234622\n",
      "             Cash_Flow_Ratios_PC2    0.171366\n",
      "                Growth_Ratios_PC2   -0.019144\n",
      "              Leverage_Ratios_PC2   -0.075011\n",
      "Liquidity_and_Coverage_Ratios_PC2   -0.130918\n",
      "              Activity_Ratios_PC1   -0.171433\n",
      "                Growth_Ratios_PC1   -0.376129\n",
      "\n",
      "GradientBoosting Model:\n",
      "Feature Importance from GradientBoosting Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.685100\n",
      "      Cost_and_Expense_Ratios_PC1    0.082708\n",
      "              Activity_Ratios_PC2    0.038379\n",
      "             Cash_Flow_Ratios_PC2    0.027321\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.024900\n",
      "              Activity_Ratios_PC1    0.024166\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.019856\n",
      "             Per_Share_Ratios_PC1    0.016967\n",
      "         Profitability_Ratios_PC1    0.015384\n",
      "         Profitability_Ratios_PC2    0.013736\n",
      "\n",
      "KNN Model:\n",
      "Feature Importance from KNN Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "NaiveBayes Model:\n",
      "Feature Importance from NaiveBayes Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "\n",
      "_______________________________________________________________________________\n",
      " Total time taken by KMSMOTE_MICE_3_PCA: 90.88 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 01:56:02,407 - INFO - ANN has been trained in 174.12 seconds\n",
      "2024-07-23 02:13:29,891 - INFO - RandomForest has been trained in 1047.48 seconds\n",
      "2024-07-23 02:13:43,355 - INFO - XGBoost has been trained in 13.46 seconds\n",
      "2024-07-23 02:26:38,493 - INFO - SVM has been trained in 775.14 seconds\n",
      "2024-07-23 02:26:39,092 - INFO - LogisticRegression has been trained in 0.60 seconds\n",
      "2024-07-23 03:16:30,991 - INFO - GradientBoosting has been trained in 2991.90 seconds\n",
      "2024-07-23 03:16:33,806 - INFO - KNN has been trained in 2.81 seconds\n",
      "2024-07-23 03:16:33,813 - INFO - Naive Bayes has been trained in 0.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 03:16:36,310 - INFO - Models have been tested in 2.50 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 542us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 03:16:38,764 - INFO - Models have been evaluated in 2.45 seconds\n",
      "2024-07-23 03:19:19,905 - INFO - SHAP explanations for RandomForest created and saved\n",
      "2024-07-23 03:19:21,376 - INFO - SHAP explanations for XGBoost created and saved\n",
      "2024-07-23 03:19:22,741 - INFO - SHAP explanations for SVM created and saved\n",
      "2024-07-23 03:19:24,102 - INFO - SHAP explanations for LogisticRegression created and saved\n",
      "2024-07-23 03:19:43,511 - INFO - SHAP explanations for GradientBoosting created and saved\n",
      "2024-07-23 03:20:02,962 - INFO - SHAP explanations for KNN created and saved\n",
      "2024-07-23 03:20:22,446 - INFO - SHAP explanations for NaiveBayes created and saved\n",
      "2024-07-23 03:20:22,862 - INFO - LIME explanation for RandomForest created and saved\n",
      "2024-07-23 03:20:23,160 - INFO - LIME explanation for XGBoost created and saved\n",
      "2024-07-23 03:20:25,196 - INFO - LIME explanation for SVM created and saved\n",
      "2024-07-23 03:20:25,470 - INFO - LIME explanation for LogisticRegression created and saved\n",
      "2024-07-23 03:20:25,799 - INFO - LIME explanation for GradientBoosting created and saved\n",
      "2024-07-23 03:20:26,182 - INFO - LIME explanation for KNN created and saved\n",
      "2024-07-23 03:20:26,645 - INFO - LIME explanation for NaiveBayes created and saved\n",
      "2024-07-23 03:20:26,646 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024-07-23 03:20:26,664 - INFO - ANN model saved\n",
      "2024-07-23 03:20:26,725 - INFO - RandomForest model saved\n",
      "2024-07-23 03:20:26,734 - INFO - XGBoost model saved\n",
      "2024-07-23 03:20:26,736 - INFO - SVM model saved\n",
      "2024-07-23 03:20:26,738 - INFO - LogisticRegression model saved\n",
      "2024-07-23 03:20:26,768 - INFO - GradientBoosting model saved\n",
      "2024-07-23 03:20:26,772 - INFO - KNN model saved\n",
      "2024-07-23 03:20:26,774 - INFO - NaiveBayes model saved\n",
      "2024-07-23 03:20:26,774 - INFO - Models have been saved\n",
      "2024-07-23 03:20:26,805 - INFO - Model interpretation summary created\n",
      "2024-07-23 03:20:26,807 - INFO - Results have been documented.\n",
      "2024-07-23 03:20:26,829 - INFO - Dataset has been split and returned\n",
      "2024-07-23 03:20:26,840 - INFO - Data has been standardized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Interpretation Summary:\n",
      "\n",
      "RandomForest Model:\n",
      "Feature Importance from RandomForest Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.274142\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.205798\n",
      "      Cost_and_Expense_Ratios_PC1    0.147311\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.081293\n",
      "      Cost_and_Expense_Ratios_PC2    0.064461\n",
      "         Profitability_Ratios_PC1    0.039987\n",
      "             Cash_Flow_Ratios_PC2    0.031349\n",
      "             Cash_Flow_Ratios_PC1    0.029869\n",
      "              Activity_Ratios_PC2    0.018811\n",
      "         Profitability_Ratios_PC2    0.018784\n",
      "\n",
      "XGBoost Model:\n",
      "Feature Importance from XGBoost Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.505651\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.090656\n",
      "      Cost_and_Expense_Ratios_PC1    0.069397\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.061130\n",
      "             Cash_Flow_Ratios_PC1    0.036352\n",
      "             Per_Share_Ratios_PC2    0.031088\n",
      "      Cost_and_Expense_Ratios_PC2    0.028701\n",
      "              Activity_Ratios_PC1    0.023663\n",
      "             Cash_Flow_Ratios_PC2    0.023219\n",
      "              Leverage_Ratios_PC2    0.022138\n",
      "\n",
      "SVM Model:\n",
      "Feature Importance from SVM Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "LogisticRegression Model:\n",
      "Feature Importance from LogisticRegression Model:\n",
      "                          Feature  Importance\n",
      "         Profitability_Ratios_PC2    3.759163\n",
      "              Leverage_Ratios_PC1    2.403141\n",
      "         Profitability_Ratios_PC1    1.123301\n",
      "             Cash_Flow_Ratios_PC2    0.914991\n",
      "             Per_Share_Ratios_PC1    0.634283\n",
      "             Per_Share_Ratios_PC2    0.218783\n",
      "                Growth_Ratios_PC2    0.011864\n",
      "              Leverage_Ratios_PC2   -0.032254\n",
      "Liquidity_and_Coverage_Ratios_PC2   -0.376269\n",
      "                Growth_Ratios_PC1   -0.567703\n",
      "\n",
      "GradientBoosting Model:\n",
      "Feature Importance from GradientBoosting Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.639597\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.078551\n",
      "      Cost_and_Expense_Ratios_PC1    0.064576\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.058618\n",
      "             Cash_Flow_Ratios_PC1    0.024636\n",
      "         Profitability_Ratios_PC1    0.018548\n",
      "             Cash_Flow_Ratios_PC2    0.018065\n",
      "      Cost_and_Expense_Ratios_PC2    0.017804\n",
      "              Leverage_Ratios_PC2    0.013303\n",
      "         Profitability_Ratios_PC2    0.012445\n",
      "\n",
      "KNN Model:\n",
      "Feature Importance from KNN Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "NaiveBayes Model:\n",
      "Feature Importance from NaiveBayes Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "\n",
      "_______________________________________________________________________________\n",
      " Total time taken by SVMSMOTE_AE_3_PCA: 87.31 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 03:23:21,109 - INFO - ANN has been trained in 174.27 seconds\n",
      "2024-07-23 03:40:55,334 - INFO - RandomForest has been trained in 1054.23 seconds\n",
      "2024-07-23 03:41:08,770 - INFO - XGBoost has been trained in 13.44 seconds\n",
      "2024-07-23 03:53:50,976 - INFO - SVM has been trained in 762.20 seconds\n",
      "2024-07-23 03:53:51,713 - INFO - LogisticRegression has been trained in 0.74 seconds\n",
      "2024-07-23 04:43:44,535 - INFO - GradientBoosting has been trained in 2992.82 seconds\n",
      "2024-07-23 04:43:47,360 - INFO - KNN has been trained in 2.82 seconds\n",
      "2024-07-23 04:43:47,369 - INFO - Naive Bayes has been trained in 0.01 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 04:43:49,701 - INFO - Models have been tested in 2.33 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 04:43:52,133 - INFO - Models have been evaluated in 2.43 seconds\n",
      "2024-07-23 04:47:47,510 - INFO - SHAP explanations for RandomForest created and saved\n",
      "2024-07-23 04:47:48,966 - INFO - SHAP explanations for XGBoost created and saved\n",
      "2024-07-23 04:47:50,296 - INFO - SHAP explanations for SVM created and saved\n",
      "2024-07-23 04:47:51,705 - INFO - SHAP explanations for LogisticRegression created and saved\n",
      "2024-07-23 04:48:10,533 - INFO - SHAP explanations for GradientBoosting created and saved\n",
      "2024-07-23 04:48:29,406 - INFO - SHAP explanations for KNN created and saved\n",
      "2024-07-23 04:48:48,117 - INFO - SHAP explanations for NaiveBayes created and saved\n",
      "2024-07-23 04:48:48,566 - INFO - LIME explanation for RandomForest created and saved\n",
      "2024-07-23 04:48:48,871 - INFO - LIME explanation for XGBoost created and saved\n",
      "2024-07-23 04:48:50,785 - INFO - LIME explanation for SVM created and saved\n",
      "2024-07-23 04:48:51,066 - INFO - LIME explanation for LogisticRegression created and saved\n",
      "2024-07-23 04:48:51,398 - INFO - LIME explanation for GradientBoosting created and saved\n",
      "2024-07-23 04:48:51,814 - INFO - LIME explanation for KNN created and saved\n",
      "2024-07-23 04:48:52,094 - INFO - LIME explanation for NaiveBayes created and saved\n",
      "2024-07-23 04:48:52,095 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024-07-23 04:48:52,111 - INFO - ANN model saved\n",
      "2024-07-23 04:48:52,197 - INFO - RandomForest model saved\n",
      "2024-07-23 04:48:52,205 - INFO - XGBoost model saved\n",
      "2024-07-23 04:48:52,208 - INFO - SVM model saved\n",
      "2024-07-23 04:48:52,209 - INFO - LogisticRegression model saved\n",
      "2024-07-23 04:48:52,235 - INFO - GradientBoosting model saved\n",
      "2024-07-23 04:48:52,239 - INFO - KNN model saved\n",
      "2024-07-23 04:48:52,241 - INFO - NaiveBayes model saved\n",
      "2024-07-23 04:48:52,242 - INFO - Models have been saved\n",
      "2024-07-23 04:48:52,273 - INFO - Model interpretation summary created\n",
      "2024-07-23 04:48:52,275 - INFO - Results have been documented.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Interpretation Summary:\n",
      "\n",
      "RandomForest Model:\n",
      "Feature Importance from RandomForest Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.250686\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.230570\n",
      "      Cost_and_Expense_Ratios_PC1    0.138832\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.088658\n",
      "      Cost_and_Expense_Ratios_PC2    0.056759\n",
      "         Profitability_Ratios_PC1    0.037599\n",
      "             Cash_Flow_Ratios_PC2    0.035791\n",
      "             Cash_Flow_Ratios_PC1    0.029805\n",
      "              Activity_Ratios_PC1    0.023575\n",
      "              Activity_Ratios_PC2    0.021451\n",
      "\n",
      "XGBoost Model:\n",
      "Feature Importance from XGBoost Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.511008\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.088647\n",
      "      Cost_and_Expense_Ratios_PC1    0.070526\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.058024\n",
      "             Cash_Flow_Ratios_PC1    0.039331\n",
      "             Cash_Flow_Ratios_PC2    0.036763\n",
      "             Per_Share_Ratios_PC1    0.034040\n",
      "              Activity_Ratios_PC1    0.029276\n",
      "         Profitability_Ratios_PC1    0.024291\n",
      "         Profitability_Ratios_PC2    0.019675\n",
      "\n",
      "SVM Model:\n",
      "Feature Importance from SVM Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "LogisticRegression Model:\n",
      "Feature Importance from LogisticRegression Model:\n",
      "                          Feature  Importance\n",
      "             Per_Share_Ratios_PC1    8.920448\n",
      "         Profitability_Ratios_PC2    4.447893\n",
      "              Leverage_Ratios_PC1    2.230180\n",
      "             Per_Share_Ratios_PC2    1.692527\n",
      "             Cash_Flow_Ratios_PC2    0.357021\n",
      "         Profitability_Ratios_PC1    0.270891\n",
      "              Leverage_Ratios_PC2    0.039086\n",
      "                Growth_Ratios_PC2    0.011821\n",
      "Liquidity_and_Coverage_Ratios_PC2   -0.338323\n",
      "      Cost_and_Expense_Ratios_PC2   -0.744421\n",
      "\n",
      "GradientBoosting Model:\n",
      "Feature Importance from GradientBoosting Model:\n",
      "                          Feature  Importance\n",
      "              Leverage_Ratios_PC1    0.639680\n",
      "Liquidity_and_Coverage_Ratios_PC1    0.076014\n",
      "Liquidity_and_Coverage_Ratios_PC2    0.059485\n",
      "      Cost_and_Expense_Ratios_PC1    0.057744\n",
      "             Cash_Flow_Ratios_PC1    0.027832\n",
      "             Cash_Flow_Ratios_PC2    0.025762\n",
      "         Profitability_Ratios_PC1    0.020729\n",
      "              Activity_Ratios_PC1    0.018895\n",
      "             Per_Share_Ratios_PC1    0.018359\n",
      "         Profitability_Ratios_PC2    0.013879\n",
      "\n",
      "KNN Model:\n",
      "Feature Importance from KNN Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "NaiveBayes Model:\n",
      "Feature Importance from NaiveBayes Model:\n",
      "                          Feature Importance\n",
      "Liquidity_and_Coverage_Ratios_PC1       None\n",
      "Liquidity_and_Coverage_Ratios_PC2       None\n",
      "              Leverage_Ratios_PC1       None\n",
      "              Leverage_Ratios_PC2       None\n",
      "              Activity_Ratios_PC1       None\n",
      "              Activity_Ratios_PC2       None\n",
      "         Profitability_Ratios_PC1       None\n",
      "         Profitability_Ratios_PC2       None\n",
      "      Cost_and_Expense_Ratios_PC1       None\n",
      "      Cost_and_Expense_Ratios_PC2       None\n",
      "\n",
      "\n",
      "_______________________________________________________________________________\n",
      " Total time taken by SVMSMOTE_MICE_3_PCA: 88.42 mins\n",
      " \n",
      "_______________________________________________________________________________\n",
      " Total time taken by all the models : 550.36 mins\n",
      "Results for ADASYN_AE_3_PCA: {'ANN': {'accuracy': 0.9782925939438162, 'confusion_matrix': array([[2637,  105],\n",
      "       [  14, 2726]], dtype=int64), 'f1_score': 0.9786393825166039, 'precision': 0.9629106322854115, 'recall': 0.9948905109489051, 'auc_roc': 0.9924137637293894, 'g_mean': 0.9781579387245248, 'kappa': 0.9565857079520751}, 'RandomForest': {'accuracy': 0.9916089018606348, 'confusion_matrix': array([[2698,   44],\n",
      "       [   2, 2738]], dtype=int64), 'f1_score': 0.9916696848967765, 'precision': 0.9841840402588066, 'recall': 0.9992700729927008, 'auc_roc': 0.9996024932517689, 'g_mean': 0.9915821219869624, 'kappa': 0.98321789530371}, 'XGBoost': {'accuracy': 0.9928858080992339, 'confusion_matrix': array([[2703,   39],\n",
      "       [   0, 2740]], dtype=int64), 'f1_score': 0.9929335024460954, 'precision': 0.9859661748830515, 'recall': 1.0, 'auc_roc': 0.9997399202457581, 'g_mean': 0.992862933768625, 'kappa': 0.9857716881630652}, 'SVM': {'accuracy': 0.9126231302444363, 'confusion_matrix': array([[2427,  315],\n",
      "       [ 164, 2576]], dtype=int64), 'f1_score': 0.9149351802521755, 'precision': 0.8910411622276029, 'recall': 0.9401459854014599, 'auc_roc': 0.9514020880917013, 'g_mean': 0.9122183640732605, 'kappa': 0.8252497494087431}, 'LogisticRegression': {'accuracy': 0.8657424297701569, 'confusion_matrix': array([[2245,  497],\n",
      "       [ 239, 2501]], dtype=int64), 'f1_score': 0.8717323109097247, 'precision': 0.8342228152101401, 'recall': 0.9127737226277373, 'auc_roc': 0.9053999158800384, 'g_mean': 0.8644821133632805, 'kappa': 0.731494044324906}, 'GradientBoosting': {'accuracy': 0.990879241152864, 'confusion_matrix': array([[2693,   49],\n",
      "       [   1, 2739]], dtype=int64), 'f1_score': 0.9909551374819102, 'precision': 0.9824246771879483, 'recall': 0.9996350364963503, 'auc_roc': 0.9995835263300803, 'g_mean': 0.990843777138772, 'kappa': 0.981758596419494}, 'KNN': {'accuracy': 0.9844947099598687, 'confusion_matrix': array([[2657,   85],\n",
      "       [   0, 2740]], dtype=int64), 'f1_score': 0.9847259658580413, 'precision': 0.9699115044247788, 'recall': 1.0, 'auc_roc': 0.9908516879894796, 'g_mean': 0.9843783466709345, 'kappa': 0.9689897666296428}, 'NaiveBayes': {'accuracy': 0.5361182050346589, 'confusion_matrix': array([[ 300, 2442],\n",
      "       [ 101, 2639]], dtype=int64), 'f1_score': 0.6748497634573584, 'precision': 0.5193859476481008, 'recall': 0.9631386861313869, 'auc_roc': 0.7088907611791702, 'g_mean': 0.32461704185944773, 'kappa': 0.07252527835765965}}\n",
      "Results for ADASYN_MICE_3_PCA: {'ANN': {'accuracy': 0.9771731190650109, 'confusion_matrix': array([[2628,  114],\n",
      "       [  11, 2723]], dtype=int64), 'f1_score': 0.9775623765930712, 'precision': 0.9598167077899189, 'recall': 0.9959765910753475, 'auc_roc': 0.9907951948529393, 'g_mean': 0.9770201502225652, 'kappa': 0.9543486496003756}, 'RandomForest': {'accuracy': 0.9919649379108838, 'confusion_matrix': array([[2698,   44],\n",
      "       [   0, 2734]], dtype=int64), 'f1_score': 0.9920174165457184, 'precision': 0.9841612670986322, 'recall': 1.0, 'auc_roc': 0.999787504462006, 'g_mean': 0.9919442115086117, 'kappa': 0.9839302187972367}, 'XGBoost': {'accuracy': 0.9926953981008035, 'confusion_matrix': array([[2702,   40],\n",
      "       [   0, 2734]], dtype=int64), 'f1_score': 0.9927378358750908, 'precision': 0.9855803893294881, 'recall': 1.0, 'auc_roc': 0.9995956848865917, 'g_mean': 0.9926792573386437, 'kappa': 0.9853910768184988}, 'SVM': {'accuracy': 0.9212929145361578, 'confusion_matrix': array([[2435,  307],\n",
      "       [ 124, 2610]], dtype=int64), 'f1_score': 0.9237303132188993, 'precision': 0.8947548851559822, 'recall': 0.9546452084857352, 'auc_roc': 0.9569916634518881, 'g_mean': 0.9207394601159304, 'kappa': 0.8426008621701506}, 'LogisticRegression': {'accuracy': 0.8745434623813002, 'confusion_matrix': array([[2260,  482],\n",
      "       [ 205, 2529]], dtype=int64), 'f1_score': 0.8804177545691906, 'precision': 0.8399202922617071, 'recall': 0.9250182882223847, 'auc_roc': 0.9135752767777725, 'g_mean': 0.8731636626004577, 'kappa': 0.749123468737763}, 'GradientBoosting': {'accuracy': 0.9926953981008035, 'confusion_matrix': array([[2702,   40],\n",
      "       [   0, 2734]], dtype=int64), 'f1_score': 0.9927378358750908, 'precision': 0.9855803893294881, 'recall': 1.0, 'auc_roc': 0.9996974639798054, 'g_mean': 0.9926792573386437, 'kappa': 0.9853910768184988}, 'KNN': {'accuracy': 0.9848429510591673, 'confusion_matrix': array([[2659,   83],\n",
      "       [   0, 2734]], dtype=int64), 'f1_score': 0.9850477391460998, 'precision': 0.9705360312389066, 'recall': 1.0, 'auc_roc': 0.9916086272388066, 'g_mean': 0.9847487618662348, 'kappa': 0.9696871798702408}, 'NaiveBayes': {'accuracy': 0.5787070854638422, 'confusion_matrix': array([[ 535, 2207],\n",
      "       [ 100, 2634]], dtype=int64), 'f1_score': 0.6954455445544554, 'precision': 0.5441024581697996, 'recall': 0.9634235552304315, 'auc_roc': 0.7325007990259087, 'g_mean': 0.4335625839954397, 'kappa': 0.15835857853692237}}\n",
      "Results for KMSMOTE_AE_3_PCA: {'ANN': {'accuracy': 0.9761123267687819, 'confusion_matrix': array([[2619,  123],\n",
      "       [   8, 2734]], dtype=int64), 'f1_score': 0.9766029648151455, 'precision': 0.9569478473923696, 'recall': 0.9970824215900802, 'auc_roc': 0.992073685879378, 'g_mean': 0.9758870475588612, 'kappa': 0.9522246535375638}, 'RandomForest': {'accuracy': 0.9927060539752006, 'confusion_matrix': array([[2704,   38],\n",
      "       [   2, 2740]], dtype=int64), 'f1_score': 0.9927536231884058, 'precision': 0.986321094312455, 'recall': 0.9992706053975201, 'auc_roc': 0.9997723634459984, 'g_mean': 0.9926843487552515, 'kappa': 0.9854121079504011}, 'XGBoost': {'accuracy': 0.9912472647702407, 'confusion_matrix': array([[2697,   45],\n",
      "       [   3, 2739]], dtype=int64), 'f1_score': 0.991313789359392, 'precision': 0.9838362068965517, 'recall': 0.9989059080962801, 'auc_roc': 0.9998794982658923, 'g_mean': 0.9912176779582214, 'kappa': 0.9824945295404814}, 'SVM': {'accuracy': 0.937454412837345, 'confusion_matrix': array([[2534,  208],\n",
      "       [ 135, 2607]], dtype=int64), 'f1_score': 0.9382760482274609, 'precision': 0.9261101243339254, 'recall': 0.9507658643326039, 'auc_roc': 0.9771218280512076, 'g_mean': 0.9373598996155642, 'kappa': 0.87490882567469}, 'LogisticRegression': {'accuracy': 0.9099197665937272, 'confusion_matrix': array([[2463,  279],\n",
      "       [ 215, 2527]], dtype=int64), 'f1_score': 0.910958904109589, 'precision': 0.9005702066999287, 'recall': 0.9215900802334063, 'auc_roc': 0.9476529693702149, 'g_mean': 0.9098449238290746, 'kappa': 0.8198395331874544}, 'GradientBoosting': {'accuracy': 0.9912472647702407, 'confusion_matrix': array([[2697,   45],\n",
      "       [   3, 2739]], dtype=int64), 'f1_score': 0.991313789359392, 'precision': 0.9838362068965517, 'recall': 0.9989059080962801, 'auc_roc': 0.9995524411310457, 'g_mean': 0.9912176779582214, 'kappa': 0.9824945295404814}, 'KNN': {'accuracy': 0.9819474835886215, 'confusion_matrix': array([[2648,   94],\n",
      "       [   5, 2737]], dtype=int64), 'f1_score': 0.982235779651893, 'precision': 0.9667961850936065, 'recall': 0.9981765134938001, 'auc_roc': 0.9901743870239051, 'g_mean': 0.9818133626684671, 'kappa': 0.9638949671772429}, 'NaiveBayes': {'accuracy': 0.5565280816921955, 'confusion_matrix': array([[ 387, 2355],\n",
      "       [  77, 2665]], dtype=int64), 'f1_score': 0.6866786910590054, 'precision': 0.5308764940239044, 'recall': 0.9719183078045223, 'auc_roc': 0.8175929605706621, 'g_mean': 0.37037071396419163, 'kappa': 0.11305616338439095}}\n",
      "Results for KMSMOTE_MICE_3_PCA: {'ANN': {'accuracy': 0.9843180160466812, 'confusion_matrix': array([[2670,   72],\n",
      "       [  14, 2728]], dtype=int64), 'f1_score': 0.9844821364128473, 'precision': 0.9742857142857143, 'recall': 0.9948942377826404, 'auc_roc': 0.9949201735863392, 'g_mean': 0.9842611951346383, 'kappa': 0.9686360320933625}, 'RandomForest': {'accuracy': 0.9932530999270606, 'confusion_matrix': array([[2708,   34],\n",
      "       [   3, 2739]], dtype=int64), 'f1_score': 0.9932910244786944, 'precision': 0.9877389109267941, 'recall': 0.9989059080962801, 'auc_roc': 0.9997158366943475, 'g_mean': 0.9932370141484445, 'kappa': 0.9865061998541211}, 'XGBoost': {'accuracy': 0.9934354485776805, 'confusion_matrix': array([[2708,   34],\n",
      "       [   2, 2740]], dtype=int64), 'f1_score': 0.9934735315445975, 'precision': 0.9877433309300648, 'recall': 0.9992706053975201, 'auc_roc': 0.9996499331521286, 'g_mean': 0.9934183114054347, 'kappa': 0.986870897155361}, 'SVM': {'accuracy': 0.9412837345003647, 'confusion_matrix': array([[2533,  209],\n",
      "       [ 113, 2629]], dtype=int64), 'f1_score': 0.9422939068100359, 'precision': 0.9263565891472868, 'recall': 0.9587892049598833, 'auc_roc': 0.9775421210752478, 'g_mean': 0.9411209419298584, 'kappa': 0.8825674690007294}, 'LogisticRegression': {'accuracy': 0.9144784828592268, 'confusion_matrix': array([[2475,  267],\n",
      "       [ 202, 2540]], dtype=int64), 'f1_score': 0.9154802667147234, 'precision': 0.9048806555040969, 'recall': 0.9263311451495259, 'auc_roc': 0.9521755750167187, 'g_mean': 0.9144016677637598, 'kappa': 0.8289569657184537}, 'GradientBoosting': {'accuracy': 0.9938001458789205, 'confusion_matrix': array([[2710,   32],\n",
      "       [   2, 2740]], dtype=int64), 'f1_score': 0.9938338774029742, 'precision': 0.9884559884559885, 'recall': 0.9992706053975201, 'auc_roc': 0.9996311795709925, 'g_mean': 0.9937850894542638, 'kappa': 0.987600291757841}, 'KNN': {'accuracy': 0.9806710430342815, 'confusion_matrix': array([[2644,   98],\n",
      "       [   8, 2734]], dtype=int64), 'f1_score': 0.9809831359885182, 'precision': 0.9653954802259888, 'recall': 0.9970824215900802, 'auc_roc': 0.9903110487587788, 'g_mean': 0.9805337124749174, 'kappa': 0.9613420860685631}, 'NaiveBayes': {'accuracy': 0.5906272793581328, 'confusion_matrix': array([[ 576, 2166],\n",
      "       [  79, 2663]], dtype=int64), 'f1_score': 0.7034737815348039, 'precision': 0.551459929592048, 'recall': 0.9711889132020423, 'auc_roc': 0.8436326404882635, 'g_mean': 0.4516784541773538, 'kappa': 0.1812545587162655}}\n",
      "Results for SVMSMOTE_AE_3_PCA: {'ANN': {'accuracy': 0.9797592997811816, 'confusion_matrix': array([[2636,  106],\n",
      "       [   5, 2737]], dtype=int64), 'f1_score': 0.9801253357206804, 'precision': 0.9627154414351038, 'recall': 0.9981765134938001, 'auc_roc': 0.9942729755309659, 'g_mean': 0.9795861839301201, 'kappa': 0.9595185995623632}, 'RandomForest': {'accuracy': 0.9943471918307805, 'confusion_matrix': array([[2715,   27],\n",
      "       [   4, 2738]], dtype=int64), 'f1_score': 0.9943708007989831, 'precision': 0.9902350813743219, 'recall': 0.9985412107950401, 'auc_roc': 0.9998558900343204, 'g_mean': 0.9943383468954048, 'kappa': 0.9886943836615609}, 'XGBoost': {'accuracy': 0.9950765864332604, 'confusion_matrix': array([[2717,   25],\n",
      "       [   2, 2740]], dtype=int64), 'f1_score': 0.9950971490829853, 'precision': 0.9909584086799277, 'recall': 0.9992706053975201, 'auc_roc': 0.9999237886383624, 'g_mean': 0.9950677479813108, 'kappa': 0.9901531728665208}, 'SVM': {'accuracy': 0.9385485047410649, 'confusion_matrix': array([[2532,  210],\n",
      "       [ 127, 2615]], dtype=int64), 'f1_score': 0.9394647027124124, 'precision': 0.9256637168141593, 'recall': 0.9536834427425237, 'auc_roc': 0.9774447620582866, 'g_mean': 0.9384264645689511, 'kappa': 0.8770970094821299}, 'LogisticRegression': {'accuracy': 0.9042669584245077, 'confusion_matrix': array([[2500,  242],\n",
      "       [ 283, 2459]], dtype=int64), 'f1_score': 0.9035458386918979, 'precision': 0.9104035542391706, 'recall': 0.8967906637490882, 'auc_roc': 0.9536464010946771, 'g_mean': 0.9042360516569976, 'kappa': 0.8085339168490153}, 'GradientBoosting': {'accuracy': 0.9932530999270606, 'confusion_matrix': array([[2706,   36],\n",
      "       [   1, 2741]], dtype=int64), 'f1_score': 0.9932958869360391, 'precision': 0.9870363701836514, 'recall': 0.99963530269876, 'auc_roc': 0.9997000757059459, 'g_mean': 0.9932325951168216, 'kappa': 0.9865061998541211}, 'KNN': {'accuracy': 0.9899708242159008, 'confusion_matrix': array([[2688,   54],\n",
      "       [   1, 2741]], dtype=int64), 'f1_score': 0.9900668231894528, 'precision': 0.9806797853309481, 'recall': 0.99963530269876, 'auc_roc': 0.9936007727007443, 'g_mean': 0.9899236489014515, 'kappa': 0.9799416484318016}, 'NaiveBayes': {'accuracy': 0.5340991976659373, 'confusion_matrix': array([[ 312, 2430],\n",
      "       [ 125, 2617]], dtype=int64), 'f1_score': 0.6719732956733856, 'precision': 0.5185258569447196, 'recall': 0.9544128373450036, 'auc_roc': 0.7611977499958769, 'g_mean': 0.32954270929142687, 'kappa': 0.06819839533187455}}\n",
      "Results for SVMSMOTE_MICE_3_PCA: {'ANN': {'accuracy': 0.9812180889861415, 'confusion_matrix': array([[2645,   97],\n",
      "       [   6, 2736]], dtype=int64), 'f1_score': 0.9815246636771301, 'precision': 0.9657606777267914, 'recall': 0.9978118161925602, 'auc_roc': 0.9946710568667102, 'g_mean': 0.9810777677488236, 'kappa': 0.962436177972283}, 'RandomForest': {'accuracy': 0.9941648431801605, 'confusion_matrix': array([[2713,   29],\n",
      "       [   3, 2739]], dtype=int64), 'f1_score': 0.9941923774954627, 'precision': 0.9895231213872833, 'recall': 0.9989059080962801, 'auc_roc': 0.9999319683918364, 'g_mean': 0.9941535383022555, 'kappa': 0.9883296863603209}, 'XGBoost': {'accuracy': 0.9941648431801605, 'confusion_matrix': array([[2710,   32],\n",
      "       [   0, 2742]], dtype=int64), 'f1_score': 0.994198694706309, 'precision': 0.9884643114635905, 'recall': 1.0, 'auc_roc': 0.9998125971927618, 'g_mean': 0.9941477185812584, 'kappa': 0.9883296863603209}, 'SVM': {'accuracy': 0.9423778264040846, 'confusion_matrix': array([[2537,  205],\n",
      "       [ 111, 2631]], dtype=int64), 'f1_score': 0.9433488705629258, 'precision': 0.9277150916784203, 'recall': 0.9595185995623632, 'auc_roc': 0.978565122276009, 'g_mean': 0.9422219279944738, 'kappa': 0.8847556528081693}, 'LogisticRegression': {'accuracy': 0.9126549963530269, 'confusion_matrix': array([[2483,  259],\n",
      "       [ 220, 2522]], dtype=int64), 'f1_score': 0.9132717725873619, 'precision': 0.9068680330816253, 'recall': 0.9197665937272064, 'auc_roc': 0.9560932114164353, 'g_mean': 0.9126272884101874, 'kappa': 0.825309992706054}, 'GradientBoosting': {'accuracy': 0.9934354485776805, 'confusion_matrix': array([[2706,   36],\n",
      "       [   0, 2742]], dtype=int64), 'f1_score': 0.9934782608695653, 'precision': 0.9870410367170627, 'recall': 1.0, 'auc_roc': 0.999746095131996, 'g_mean': 0.9934137592943643, 'kappa': 0.986870897155361}, 'KNN': {'accuracy': 0.9901531728665208, 'confusion_matrix': array([[2690,   52],\n",
      "       [   2, 2740]], dtype=int64), 'f1_score': 0.9902421395012649, 'precision': 0.9813753581661891, 'recall': 0.9992706053975201, 'auc_roc': 0.9952252185390721, 'g_mean': 0.9901111948471651, 'kappa': 0.9803063457330415}, 'NaiveBayes': {'accuracy': 0.5632749817651349, 'confusion_matrix': array([[ 461, 2281],\n",
      "       [ 114, 2628]], dtype=int64), 'f1_score': 0.6869690236570383, 'precision': 0.5353432470971685, 'recall': 0.9584245076586433, 'auc_roc': 0.7830454060110416, 'g_mean': 0.40141693694791786, 'kappa': 0.12654996353026993}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_paths = [\n",
    "    \"C:\\\\Users\\\\dev\\\\Desktop\\\\MSC thesis\\\\Code\\\\final_codes\\\\Processed Datasets\\\\ADASYN_AE_3_PCA.xlsx\",\n",
    "    \"C:\\\\Users\\\\dev\\\\Desktop\\\\MSC thesis\\\\Code\\\\final_codes\\\\Processed Datasets\\\\ADASYN_MICE_RF_3_PCA.xlsx\",\n",
    "    \"C:\\\\Users\\\\dev\\\\Desktop\\\\MSC thesis\\\\Code\\\\final_codes\\\\Processed Datasets\\\\KMSMOTE_AE_3_PCA.xlsx\",\n",
    "    \"C:\\\\Users\\\\dev\\\\Desktop\\\\MSC thesis\\\\Code\\\\final_codes\\\\Processed Datasets\\\\KMSMOTE_MICE_RF_3_PCA.xlsx\",\n",
    "    \"C:\\\\Users\\\\dev\\\\Desktop\\\\MSC thesis\\\\Code\\\\final_codes\\\\Processed Datasets\\\\SVMSMOTE_AE_3_PCA.xlsx\",\n",
    "    \"C:\\\\Users\\\\dev\\\\Desktop\\\\MSC thesis\\\\Code\\\\final_codes\\\\Processed Datasets\\\\SVMSMOTE_MICE_RF_3_PCA.xlsx\"\n",
    "]\n",
    "\n",
    "# Read the Excel files into dataframes\n",
    "dfs = [pd.read_excel(file_path) for file_path in file_paths]\n",
    "\n",
    "print(\"Datasets are read into dataframes\")\n",
    "\n",
    "tot_start_time = time.time()\n",
    "start_time = time.time()\n",
    "# Store results in variables\n",
    "results_ADASYN_AE_3_PCA = modelling_gs(dfs[0], \"ADASYN_AE_3_PCA\" )\n",
    "end_time = time.time()  # End timing\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print(\"_______________________________________________________________________________\")\n",
    "print(f\" Total time taken by ADASYN_AE_3_PCA: {elapsed_time:.2f} mins\")\n",
    "\n",
    "start_time = time.time()\n",
    "results_ADASYN_MICE_3_PCA = modelling_gs(dfs[1], \"ADASYN_MICE_RF_3_PCA\")\n",
    "\n",
    "end_time = time.time()  # End timing\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print(\"_______________________________________________________________________________\")\n",
    "print(f\" Total time taken by ADASYN_MICE_3_PCA: {elapsed_time:.2f} mins\")\n",
    "\n",
    "start_time = time.time()\n",
    "results_KMSMOTE_AE_3_PCA = modelling_gs(dfs[2], \"KMSMOTE_AE_3_PCA\")\n",
    "\n",
    "end_time = time.time()  #End timing\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print(\"_______________________________________________________________________________\")\n",
    "print(f\" Total time taken by KMSMOTE_AE_3_PCA: {elapsed_time:.2f} mins\")\n",
    "\n",
    "start_time = time.time()\n",
    "results_KMSMOTE_MICE_3_PCA = modelling_gs(dfs[3], \"KMSMOTE_MICE_RF_3_PCA\")\n",
    "\n",
    "end_time = time.time()  # end timing\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print(\"_______________________________________________________________________________\")\n",
    "print(f\" Total time taken by KMSMOTE_MICE_3_PCA: {elapsed_time:.2f} mins\")\n",
    "\n",
    "start_time = time.time()\n",
    "results_SVMSMOTE_AE_3_PCA = modelling_gs(dfs[4], \"SVMSMOTE_AE_3_PCA\")\n",
    "\n",
    "end_time = time.time()  # End timing\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print(\"_______________________________________________________________________________\")\n",
    "print(f\" Total time taken by SVMSMOTE_AE_3_PCA: {elapsed_time:.2f} mins\")\n",
    "\n",
    "start_time = time.time()\n",
    "results_SVMSMOTE_MICE_3_PCA = modelling_gs(dfs[5], \"SVMSMOTE_MICE_RF_3_PCA\")\n",
    "\n",
    "end_time = time.time()  # End timing\n",
    "elapsed_time = (end_time - start_time) / 60\n",
    "print(\"_______________________________________________________________________________\")\n",
    "print(f\" Total time taken by SVMSMOTE_MICE_3_PCA: {elapsed_time:.2f} mins\")\n",
    "\n",
    "\n",
    "print(\" \")\n",
    "print(\"_______________________________________________________________________________\")\n",
    "tot_end_time = time.time()  # End timing\n",
    "tot_elapsed_time = (tot_end_time - tot_start_time) / 60\n",
    "print(f\" Total time taken by all the models : {tot_elapsed_time:.2f} mins\")\n",
    "\n",
    "# Print the all final results with variable names\n",
    "print(\"Results for ADASYN_AE_3_PCA:\", results_ADASYN_AE_3_PCA)\n",
    "print(\"Results for ADASYN_MICE_3_PCA:\", results_ADASYN_MICE_3_PCA)\n",
    "print(\"Results for KMSMOTE_AE_3_PCA:\", results_KMSMOTE_AE_3_PCA)\n",
    "print(\"Results for KMSMOTE_MICE_3_PCA:\", results_KMSMOTE_MICE_3_PCA)\n",
    "print(\"Results for SVMSMOTE_AE_3_PCA:\", results_SVMSMOTE_AE_3_PCA)\n",
    "print(\"Results for SVMSMOTE_MICE_3_PCA:\", results_SVMSMOTE_MICE_3_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the above are MICE_RF datasets results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
